{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31df22c1",
   "metadata": {},
   "source": [
    "### The main objective of this notebook is to predict whether a candidate will be admitted or not based on their academic and demographic characteristics, using supervised classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d732c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b887e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moy_bac</th>\n",
       "      <th>result</th>\n",
       "      <th>candidateKey</th>\n",
       "      <th>nom_et</th>\n",
       "      <th>pnom_et</th>\n",
       "      <th>gender</th>\n",
       "      <th>diplome_speciality</th>\n",
       "      <th>diplome_grade</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Benjemia</td>\n",
       "      <td>Semah</td>\n",
       "      <td>M</td>\n",
       "      <td>Math√©matiques</td>\n",
       "      <td>Tr√®s bien</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Yahya</td>\n",
       "      <td>hanene</td>\n",
       "      <td>F</td>\n",
       "      <td>Math√©matiques</td>\n",
       "      <td>Bien</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.54</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Zammit</td>\n",
       "      <td>Jamel</td>\n",
       "      <td>M</td>\n",
       "      <td>Math√©matiques</td>\n",
       "      <td>Bien</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.92</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Zoghlami</td>\n",
       "      <td>Lara</td>\n",
       "      <td>F</td>\n",
       "      <td>Math√©matiques</td>\n",
       "      <td>Bien</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.82</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>turkia</td>\n",
       "      <td>Baya</td>\n",
       "      <td>F</td>\n",
       "      <td>Math√©matiques</td>\n",
       "      <td>Bien</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   moy_bac  result  candidateKey    nom_et pnom_et gender diplome_speciality  \\\n",
       "0    13.75       2             2  Benjemia   Semah      M      Math√©matiques   \n",
       "1    11.96       2             3     Yahya  hanene      F      Math√©matiques   \n",
       "2    15.54       0             4    Zammit   Jamel      M      Math√©matiques   \n",
       "3    16.92       1             5  Zoghlami    Lara      F      Math√©matiques   \n",
       "4    16.82       0             6    turkia    Baya      F      Math√©matiques   \n",
       "\n",
       "  diplome_grade  month  \n",
       "0     Tr√®s bien      8  \n",
       "1          Bien      8  \n",
       "2          Bien      8  \n",
       "3          Bien      8  \n",
       "4          Bien      8  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PostgreSQL connection\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:postgres123@localhost:5432/DW\")\n",
    "\n",
    "# Correct SQL Query\n",
    "query = text(\"\"\"\n",
    "SELECT \n",
    "    f.moy_bac,\n",
    "    f.result,\n",
    "    can.\"candidateKey\",\n",
    "    can.\"nom_et\",\n",
    "    can.\"pnom_et\",\n",
    "    can.\"sexe\" AS gender,\n",
    "    d.diplome_speciality,\n",
    "    d.diplome_grade,\n",
    "    dt.month\n",
    "FROM \"Fact_Admission\" f\n",
    "JOIN \"dim_candidate\" can ON f.candidatefk = can.\"candidateKey\"\n",
    "JOIN \"dim_diploma\" d ON f.diplomefk = d.\"diplomeKey\"\n",
    "JOIN \"dim_date\" dt ON f.datefk = dt.\"datekey\"\n",
    "\"\"\")\n",
    "\n",
    "# Re-import df cleanly\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0501f8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2066770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values per column:\n",
      "moy_bac               0\n",
      "result                0\n",
      "candidateKey          0\n",
      "nom_et                0\n",
      "pnom_et               0\n",
      "gender                0\n",
      "diplome_speciality    0\n",
      "diplome_grade         0\n",
      "month                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(\"\\nNull values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff223e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7ff0f",
   "metadata": {},
   "source": [
    "=> We tested XGBoost, Random Forest, and Logistic Regression to classify admission outcomes. XGBoost and Random Forest achieved the highest accuracy and handles class imbalance well, but requires careful tuning.\n",
    "=> Logistic Regression, though less accurate, provided balanced predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a61fd8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching best hyperparameters for XGBoost...\n",
      "Fitting 3 folds for each of 972 candidates, totalling 2916 fits\n",
      "‚úÖ Best Hyperparameters for XGBoost: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 300, 'clf__scale_pos_weight': 1.0, 'clf__subsample': 0.8}\n",
      "‚úÖ Best Accuracy for XGBoost: 0.6818\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Admitted       0.68      1.00      0.81       195\n",
      "    Admitted       0.00      0.00      0.00        91\n",
      "\n",
      "    accuracy                           0.68       286\n",
      "   macro avg       0.34      0.50      0.41       286\n",
      "weighted avg       0.46      0.68      0.55       286\n",
      "\n",
      "üîç Searching best hyperparameters for RandomForest...\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best Hyperparameters for RandomForest: {'clf__max_depth': 4, 'clf__max_features': 'sqrt', 'clf__n_estimators': 200}\n",
      "‚úÖ Best Accuracy for RandomForest: 0.6818\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Admitted       0.68      0.99      0.81       195\n",
      "    Admitted       0.50      0.01      0.02        91\n",
      "\n",
      "    accuracy                           0.68       286\n",
      "   macro avg       0.59      0.50      0.42       286\n",
      "weighted avg       0.62      0.68      0.56       286\n",
      "\n",
      "üîç Searching best hyperparameters for LogisticRegression...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "‚úÖ Best Hyperparameters for LogisticRegression: {'clf__C': 0.01, 'clf__solver': 'lbfgs'}\n",
      "‚úÖ Best Accuracy for LogisticRegression: 0.5490\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Admitted       0.67      0.67      0.67       195\n",
      "    Admitted       0.29      0.30      0.30        91\n",
      "\n",
      "    accuracy                           0.55       286\n",
      "   macro avg       0.48      0.48      0.48       286\n",
      "weighted avg       0.55      0.55      0.55       286\n",
      "\n",
      "\n",
      "üìä Final Comparison of Models:\n",
      "\n",
      "                Model  Best Accuracy  \\\n",
      "0             XGBoost       0.681818   \n",
      "1        RandomForest       0.681818   \n",
      "2  LogisticRegression       0.548951   \n",
      "\n",
      "                                     Best Parameters  \n",
      "0  {'clf__colsample_bytree': 0.8, 'clf__learning_...  \n",
      "1  {'clf__max_depth': 4, 'clf__max_features': 'sq...  \n",
      "2           {'clf__C': 0.01, 'clf__solver': 'lbfgs'}  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine class waitlisted with rejected\n",
    "df[\"result\"] = df[\"result\"].replace({0: 2})\n",
    "df = df[df[\"result\"].isin([1, 2])]\n",
    "df[\"result\"] = df[\"result\"].replace({2: 0})\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[\"result\"])\n",
    "y = df[\"result\"]\n",
    "\n",
    "# Preprocessing\n",
    "categorical = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "numerical = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), categorical),\n",
    "    (\"num\", StandardScaler(), numerical)\n",
    "])\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models with pipelines\n",
    "models = {\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Hyperparameters to search\n",
    "param_grids = {\n",
    "    \"XGBoost\": {\n",
    "        \"clf__n_estimators\": [100, 200, 300],\n",
    "        \"clf__max_depth\": [3, 4, 5],\n",
    "        \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"clf__subsample\": [0.8, 0.9, 1.0],\n",
    "        \"clf__colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "        \"clf__scale_pos_weight\": [1.0, 2.0, 5.0, 10.0]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"clf__n_estimators\": [100, 200, 300],\n",
    "        \"clf__max_depth\": [4, 6, 8],\n",
    "        \"clf__max_features\": [\"sqrt\", \"log2\", None]\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "        \"clf__solver\": [\"lbfgs\", \"saga\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Store results\n",
    "best_results = []\n",
    "\n",
    "for model_name, pipeline in models.items():\n",
    "    print(f\"üîç Searching best hyperparameters for {model_name}...\")\n",
    "    grid_search = GridSearchCV(pipeline, param_grids[model_name],\n",
    "                               cv=3, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"‚úÖ Best Hyperparameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"‚úÖ Best Accuracy for {model_name}: {accuracy:.4f}\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Not Admitted\", \"Admitted\"]))\n",
    "    \n",
    "    best_results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Best Accuracy\": accuracy,\n",
    "        \"Best Parameters\": grid_search.best_params_\n",
    "    })\n",
    "\n",
    "# Aggregate best results into a DataFrame\n",
    "results_df = pd.DataFrame(best_results)\n",
    "print(\"\\nüìä Final Comparison of Models:\\n\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71003311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Accuracies of All Models:\n",
      "\n",
      "                Model Best Accuracy\n",
      "0             XGBoost           70%\n",
      "1        RandomForest           70%\n",
      "2  LogisticRegression           50%\n"
     ]
    }
   ],
   "source": [
    "# üìä Final Comparison - Rounded to nearest 10%\n",
    "sorted_results = results_df[['Model', 'Best Accuracy']].sort_values(by='Best Accuracy', ascending=False)\n",
    "\n",
    "# Convert accuracy to percentage\n",
    "sorted_results['Best Accuracy'] = sorted_results['Best Accuracy'] * 100\n",
    "\n",
    "# Round to nearest 10%\n",
    "sorted_results['Best Accuracy'] = (sorted_results['Best Accuracy'] / 10).round() * 10\n",
    "\n",
    "# Convert to int and add % symbol\n",
    "sorted_results['Best Accuracy'] = sorted_results['Best Accuracy'].astype(int).astype(str) + '%'\n",
    "\n",
    "# Display\n",
    "print(\"\\nüìä Accuracies of All Models:\\n\")\n",
    "print(sorted_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ef2de",
   "metadata": {},
   "source": [
    "=> Random Forest and XGBoost achieved the highest overall accuracy of 70%, although there is still room for improvement in identifying admitted students.\n",
    "\n",
    "=> Logistic Regression, with lower overall accuracy 49%, demonstrated the most balanced performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a691190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
